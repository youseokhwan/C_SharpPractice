# 합성곱 신경망

### 개요
* Keras를 GPU로 연산하도록 설정
> http://bit.ly/KerasUsingGPU
* 합성곱 신경망(Convolutional Neural Network)는 컨브넷(Convnet)이라고도 불림
* 이 모델은 거의 컴퓨터 비전 어플리케이션(Computer Vision App.)에 사용

### 기본적인 Convnet
* Conv2D와 MaxPooling2D를 쌓아올려 구성
* Convnet이 (image_height, image_width, image_channels) 크기의 입력 텐서 사용
* Output도 (height, width, channels) 크기의 3D 텐서
* 이 Output을 이전에 배운 Dense 층에 넣어야 하기 때문에 Flatten() 사용
* MNIST 모델 기준 2장에서 진행한 것보다 높은 정확도를 보임

### Why? (Dense보다 Convnet이 더 높은 정확도를 보이는 이유)
* Dense는 전역 패턴을 분석(모든 픽셀을 분석?)하는데 반해 Convent은 지역 패턴을 학습
* 위에 예에서는 3x3 Size의 Window 사용
* 지역 패턴 학습은 Translation Invariant(평행이동 불변성)을 가짐 -> 같은 패턴이 다른 위치에 나타나도 똑같이 인식
* 또한, 공간적 계층 구조를 학습할 수 있음 -> 첫 번째 Conv2D는 edge같은 작은 지역 패턴을 학습하고, 두 번째 Conv2D는 그것들이 구성된 더 큰 패턴을 학습하는 등의 흐름
* 3x3 크기의 Window가 Sliding(슬라이딩)하면서 특성 추출
* Border effect? 때문에 출력 특성 맵의 크기가 살짝 줄어듬 -> Padding(or zero padding) 설정으로 해결 가능
* 연속적인 윈도우 사이의 거리 : Stride(스트라이드)  // 드물게 사용되며, 스트라이드보다는 Max Pooling 연산을 사용하는 경우가 많음

### Max Pooling
* 최대 풀링 연산 : 강제적으로 특성 맵을 다운샘플링
* 합성곱은 선형 변환(합성곱 커널)을 적용하지만, Max Pooling은 하드코딩된 최댓값 추출 연산을 적용
* 합성곱은 전형적으로 3x3 Size에 Stride 1을 사용하지만, Max Pooling은 보통 2x2 Size에 Stride 2를 사용

### Why? (Max Pooling Layer가 없다면)
* 공간적 계층 구조 학습이 안됨
* 너무 너무 많은 크기의 weight 파라미터가 생김(약 1만5천개) -> 매우 overfitting

### 데이터 전처리
* 대략의 다음 과정을 따름
> 1. 사진 파일을 읽는다.
> 2. JPEG 콘텐츠를 RGB 픽셀 값으로 디코딩
> 3. 부동 소수 타입의 텐서로 변환
> 4. 픽셀 값(0~255)을 [0, 1]로 조정
* ImageDataGenerator는 이미지 파일을 전처리된 배치 텐서로 자동으로 바꿔주는 Python Generator를 만들어 줌
* Generator는 무한 반복하는 특성이 있기 때문에 break를 반드시 사용해야 함

### Data Augmentation(데이터 증식)
* 적은 훈련 샘플로부터 더 많은 훈련 데이터를 생성하는 방법
* 데이터를 여러 변환을 사용하여 샘플을 늘려서 일반화에 기여
* 위에서 scale 조정할 때 사용했던 ImageDataGenerator 클래스안에 rotation_range, width_shift_range, zoom_range 등 파라미터를 주어 data augment (파라미터 종류 매우 많음)
* 적은 수의 원본에서 만들어졌기 때문에 여전히 overfitting의 가능성이 조금 남아있음 -> Flatten() 직후에 Dropout 층 하나 추가

### Pretrained Network(사전 훈련된 네트워크) 사용
* 사전에 학습된 특성을 다른 문제에서도 사용 가능한 유연성은 딥러닝의 장점
* 강아지, 고양이 뿐만 아니라 약 1,000개의 클래스, 1,400만개의 레이블로 이뤄진 ImageNet의 사전 훈련된 Convnet 사용할 것
* 사용하는 방법 2가지: Featured Extraction(특성 추출), Fine Tuning(미세 조정)

### Featured Extraction(특성 추출)
* Pretrained Network에서 원하는 Feature만 추출
* Network를 Convolutional Base와 Dense Layer부분?으로 나눈다. (Flatten 이전과 이후로 나누면,,, 용어를 정확히 모르겠음)
* Pretrained Network의 Dense 부분은 버리고 Convolution Layer만 재사용한다 (일반적으로!)
* 이 부분이 말이 좀 어려운데,, 대충 쓰자면,,
* Convolutional Base는 저수준의 학습만 되어있고, 그 1,000개의 클래스에 대해 맞춰져 있지는 않다.
* 그러나 Dense Layer 쪽은 그 클래스에 특성에 맞게 학습이 되어있기 때문에, ... 안된다 ... (위치정보같은 문제도 있다.)
* 하튼 그래서 Pretrained Network의 Convolution Layer만 쓰고 Dense Layer는 새로 학습한다.

### 예제 부분 설명
* 여기선 ImageNet에도 고양이, 강아지가 있고 문제에도 고양이vs강아지여서 Dense 층을 사실 써도는 되는데, 배우는 과정이니까 안쓰는 것 같음
* ImageNet 데이터셋에 훈련된 4개 중 하나인 VGG16이라는 Convolutional Base를 사용
* 여러 층의 Convnet과 MaxPooling을 거쳐 (4, 4, 512) 완성 -> 이 위에 완전 연결 층을 놓을 것
* 이 때 2가지 방식이 있다.
> 1. 이 Output을 다시 독립된 Dense 층의 입력으로 사용하는 방식(속도 빠르지만, Data Augmentation 불가)
> 2. 이 모델 위에 Dense 층을 직접 쌓는 방식(Data Augmentation 사용할 수 있지만, 비용 많이 듦)

### Data Augmentation 사용하지 않는 빠른 Featured Extraction
* ImageDataGenerator를 이용하여 Output을 Numpy 배열로 추출
* Dense 층에 넣기 위해 Flatten 작업 (2000, 4, 4, 512) -> (2000, 4*4*512)
* 규제를 위해 Dropout 층 넣고 학습하면 epoch 당 1초안에 대부분 해결됨(CPU여도 빠르게 된다고 써있는데 그건 아닌듯)
* 결과 확인해보면 90%에 이르는 정확도를 달성했지만, overfitting을 해결하지 못함(Dropout 비율을 매우 높였는데도)
* 작은 데이터셋에는 Data Augmentation이 꼭 필요하다는 것 의미함

### Data Augmentation 사용한 Featured Extraction
* model.add(conv_base) 처럼 다른 층의 모델도 추가 가능?
* VGG16은 약 1470만 개의 파라미터, 그 위의 Dense 층들은 약 200만 개의 파라미터 (엄청나게 많은 연산)
* 이때 컴파일 및 훈련하기 전에 Convonlutional Base를 Freezing(동결)하는 것이 매우매우 중요
* Freezing하지 않으면 훈련하는 동안 weight가 업데이트되기 때문에 결과가 매우 훼손됨
* conv_base.trainable = False
* 설정을 변경했으면 컴파일부터 다시 해야함(변경 후 컴파일하지 않고 학습하면 적용 안됨)
* 학습결과는 정확도는 비슷하지만 overfitting이 거의 줄어든 것을 확인할 수 있음

### Fine Tuning(미세 조정)
* Freezing했던 conv_base에서 일부 상위 층 몇 개를 unfreezing하는 것
* Fine Tuning하기 전에 한번 최상위 분류기(Dense 층)을 학습하는 게 좋음(그렇지 않으면 랜덤한 초깃값이기 때문에 너무 큰 오차신호라서 표현이 망가질 수 있음)
* Fine Tuning 세부 단계 
> 1. Pretrained Network 위에 Dense 층 추가(위에서 언급한 2번 째 방법)
> 2. conv_base freezing
> 3. 새로 추가한 Dense 층을 학습
> 4. conv_base의 상위 층을 일부 unfreezing
> 5. 다시 학습
* 왜 상위층인가? -> 하위층으로 갈수록 저수준이여서 Fine Tuning의 효과가 감소
* 왜 전체를 하지 않는가? -> 파라미터가 1500만개임(overfitting에 매우 위험)

