# 합성곱 신경망

### 개요
* Keras를 GPU로 연산하도록 설정
> https://m.blog.naver.com/PostView.nhn?blogId=chrhdhkd&logNo=221082575543&proxyReferer=https%3A%2F%2Fwww.google.com%2F
* 합성곱 신경망(Convolutional Neural Network)는 컨브넷(Convnet)이라고도 불림
* 이 모델은 거의 컴퓨터 비전 어플리케이션(Computer Vision App.)에 사용

### 기본적인 Convnet
* Conv2D와 MaxPooling2D를 쌓아올려 구성
* Convnet이 (image_height, image_width, image_channels) 크기의 입력 텐서 사용
* Output도 (height, width, channels) 크기의 3D 텐서
* 이 Output을 이전에 배운 Dense 층에 넣어야 하기 때문에 Flatten() 사용
* MNIST 모델 기준 2장에서 진행한 것보다 높은 정확도를 보임

### Why? (Dense보다 Convnet이 더 높은 정확도를 보이는 이유)
* Dense는 전역 패턴을 분석(모든 픽셀을 분석?)하는데 반해 Convent은 지역 패턴을 학습
* 위에 예에서는 3x3 Size의 Window 사용
* 지역 패턴 학습은 Translation Invariant(평행이동 불변성)을 가짐 -> 같은 패턴이 다른 위치에 나타나도 똑같이 인식
* 또한, 공간적 계층 구조를 학습할 수 있음 -> 첫 번째 Conv2D는 edge같은 작은 지역 패턴을 학습하고, 두 번째 Conv2D는 그것들이 구성된 더 큰 패턴을 학습하는 등의 흐름
* 3x3 크기의 Window가 Sliding(슬라이딩)하면서 특성 추출
* Border effect? 때문에 출력 특성 맵의 크기가 살짝 줄어듬 -> Padding(or zero padding) 설정으로 해결 가능
* 연속적인 윈도우 사이의 거리 : Stride(스트라이드)  // 드물게 사용되며, 스트라이드보다는 Max Pooling 연산을 사용하는 경우가 많음

### Max Pooling
* 최대 풀링 연산 : 강제적으로 특성 맵을 다운샘플링
* 합성곱은 선형 변환(합성곱 커널)을 적용하지만, Max Pooling은 하드코딩된 최댓값 추출 연산을 적용
* 합성곱은 전형적으로 3x3 Size에 Stride 1을 사용하지만, Max Pooling은 보통 2x2 Size에 Stride 2를 사용

### Why? (Max Pooling Layer가 없다면)
* 공간적 계층 구조 학습이 안됨
* 너무 너무 많은 크기의 weight 파라미터가 생김(약 1만5천개) -> 매우 overfitting

### 데이터 전처리
* 대략의 다음 과정을 따름
> 1. 사진 파일을 읽는다.
> 2. JPEG 콘텐츠를 RGB 픽셀 값으로 디코딩
> 3. 부동 소수 타입의 텐서로 변환
> 4. 픽셀 값(0~255)을 [0, 1]로 조정
* ImageDataGenerator는 이미지 파일을 전처리된 배치 텐서로 자동으로 바꿔주는 Python Generator를 만들어 줌
* Generator는 무한 반복하는 특성이 있기 때문에 break를 반드시 사용해야 함

### Data Augmentation(데이터 증식)
* 적은 훈련 샘플로부터 더 많은 훈련 데이터를 생성하는 방법
* 데이터를 여러 변환을 사용하여 샘플을 늘려서 일반화에 기여
* 위에서 scale 조정할 때 사용했던 ImageDataGenerator 클래스안에 rotation_range, width_shift_range, zoom_range 등 파라미터를 주어 data augment (파라미터 종류 매우 많음)
* 적은 수의 원본에서 만들어졌기 때문에 여전히 overfitting의 가능성이 조금 남아있음 -> Flatten() 직후에 Dropout 층 하나 추가

### Pretrained Network(사전 훈련된 네트워크) 사용
* 
