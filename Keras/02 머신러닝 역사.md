# 머신러닝 역사

### 확률적 모델링
* 나이브 베이즈(Naive Bayes) 알고리즘 및 로지스틱 회귀 모델(logistic regression)
* 데이터를 분류하는 것에 초점

### 초창기 신경망
* 1989년 벨 연구소에서 합성곱 신경망(convolution neural network)과 역전파(backpropagation)를 연결하여 손글씨 숫자 이미지 분류 성공

### 커널 방법
* 분류 알고리즘 중 하나. 대표적으로 서포트 벡터 머신(Support Vector Machine), SVM이 유명
* SVM은 좋은 분류를 위해 2개의 다른 데이터포인트 범주를 결정 경계(decision boundary)를 기준으로 나눔
* 실제 적용시키기가 어려운 문제를 커널 방법으로 해결 가능
* SVM은 대용량 적용이 힘들고, 얕은 학습 방법이기 때문에 어렵고 불안정함

### 기타
* 결정 트리(decision tree)
* 랜덤 포레스트(random forest)
* 그래디언트 부스팅 머신(gradient boosting machine)

### 신경망
* 2011년 GPU로 훈련된 딥러닝으로 학술 이미지 분류 대회에서 우승하면서 유행
* 합성곱 신경망(convolution neural network)가 주력 알고리즘으로 자리
* 자연어 처리 등에도 적용되기 시작했고, SVM과 decision tree를 완전히 대체

### 딥러닝의 장점
* 이전의 얕은 학습 모델들은 정확한 정보를 얻기 위해 사람이 직접 정제하는 과정(특성 공학)이 필요
* 딥러닝은 이러한 과정을 자동화
* 층을 거치면서 점진적으로 복잡한 표현이 만들어짐
* 이런 점진적인 중간 표현이 공동으로 학습됨

### 급부상한 이유
* 하드웨어의 급격한 발전(엔비디아 CUDA, 무어의 법칙 등)
* 데이터양의 증가(인터넷의 성장)
* 알고리즘의 발전(활성 함수(activation func), RMSProp 등)
* 투자 증가, 대중화(python, tensorflow 등)
